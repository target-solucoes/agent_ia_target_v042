"""
Sistema de Filtros Autom√°ticos via JSON Response
Implementa√ß√£o simplificada que usa apenas o JSON de response do modelo
para extrair e gerenciar filtros persistentes
"""

import json
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Set, Optional, Tuple, Any, Union
import copy
import re


class JSONFilterManager:
    """
    Gerenciador de filtros que funciona exclusivamente com JSON response do modelo
    """

    def __init__(self, df_dataset: pd.DataFrame):
        """
        Inicializa o gerenciador com o dataset para valida√ß√£o

        Args:
            df_dataset: DataFrame com dados para valida√ß√£o de valores
        """
        self.df_dataset = df_dataset
        self.filtros_persistentes = {
            "periodo": {"Data": None},
            "regiao": {"UF_Cliente": [], "Municipio_Cliente": []},
            "cliente": {"Cod_Cliente": [], "Cod_Segmento_Cliente": []},
            "produto": {
                "Cod_Familia_Produto": [],
                "Cod_Grupo_Produto": [],
                "Cod_Linha_Produto": [],
                "Des_Linha_Produto": []
            },
            "representante": {"Cod_Vendedor": [], "Cod_Regiao_Vendedor": []}
        }

        # Gerar listas de valores v√°lidos diretamente do dataset
        self._gerar_valores_validos()

    def _gerar_valores_validos(self):
        """Gera listas de valores v√°lidos diretamente do dataset"""
        self.valores_validos = {}

        # Lista de colunas poss√≠veis para valida√ß√£o
        colunas_validacao = [
            "UF_Cliente", "Municipio_Cliente", "Cod_Cliente", "Cod_Segmento_Cliente",
            "Cod_Linha_Produto", "Des_Linha_Produto", "Cod_Familia_Produto",
            "Cod_Grupo_Produto", "Cod_Vendedor", "Cod_Regiao_Vendedor"
        ]

        # Apenas adicionar colunas que existem no dataset
        for coluna in colunas_validacao:
            if coluna in self.df_dataset.columns:
                self.valores_validos[coluna] = self.df_dataset[coluna].dropna().unique().tolist()

    def validar_valores(self, campo: str, valores: List[str], categoria: str) -> List[str]:
        """
        Valida valores contra o dataset com estrat√©gia mais permissiva

        Args:
            campo: Nome do campo
            valores: Lista de valores para validar
            categoria: Categoria do filtro

        Returns:
            Lista de valores v√°lidos
        """
        # Campos que sempre s√£o aceitos sem valida√ß√£o r√≠gida
        campos_permissivos = [
            'Data', 'Data_>=', 'Data_<', 'periodo', 'mes', 'ano',  # Temporais
            'cidade', 'estado', 'municipio', 'uf',  # Regionais alternativos
            'cliente', 'produto', 'linha', 'segmento'  # Gen√©ricos
        ]

        # Se √© um campo permissivo, aceitar diretamente
        if campo in campos_permissivos or campo.lower() in [c.lower() for c in campos_permissivos]:
            return valores

        # Para campos com valida√ß√£o no dataset
        if campo in self.valores_validos:
            # Converter valores para string para compara√ß√£o consistente
            valores_str = [str(v) for v in valores]
            validos_str = [str(v) for v in self.valores_validos[campo]]

            # Valida√ß√£o exata primeiro
            valores_exatos = [v for v in valores_str if v in validos_str]

            # Se n√£o encontrou exatos, tentar valida√ß√£o fuzzy (parcial)
            if not valores_exatos and valores_str:
                valores_fuzzy = []
                for valor in valores_str:
                    # Busca parcial case-insensitive
                    matches = [v for v in validos_str if valor.upper() in v.upper() or v.upper() in valor.upper()]
                    if matches:
                        valores_fuzzy.extend(matches[:1])  # Apenas primeiro match

                if valores_fuzzy:
                    return valores_fuzzy

            return valores_exatos

        # Para campos n√£o mapeados, aceitar como est√° (estrat√©gia permissiva)
        return valores

    def processar_json_response(self, response_text: str, contexto_atual: Dict) -> Tuple[Dict, List[str]]:
        """
        Processa o JSON de response do modelo para extrair filtros

        Args:
            response_text: Texto da response do modelo
            contexto_atual: Contexto atual de filtros

        Returns:
            Tuple[Dict, List[str]]: (contexto_atualizado, lista_de_mudan√ßas)
        """
        try:
            # Extrair JSON da response
            json_filtros = self._extrair_json_da_response(response_text)

            if not json_filtros:
                return contexto_atual, []

            # Processar filtros do JSON
            return self._atualizar_filtros_do_json(json_filtros, contexto_atual)

        except Exception as e:
            # Em caso de erro, retornar contexto atual inalterado
            return contexto_atual, [f"Erro ao processar JSON: {str(e)}"]

    def _extrair_json_da_response(self, response_text: str) -> Optional[Dict]:
        """
        Extrai JSON da response do modelo usando m√∫ltiplas estrat√©gias CORRIGIDAS

        Args:
            response_text: Texto da response

        Returns:
            Dict com filtros extra√≠dos ou None se n√£o encontrar
        """
        # Estrat√©gia 1: Procurar por bloco JSON entre ```json``` (mais permissivo)
        json_block_match = re.search(r'```json\s*\n?(.*?)\n?```', response_text, re.DOTALL | re.IGNORECASE)
        if json_block_match:
            json_content = json_block_match.group(1).strip()

            # CORRE√á√ÉO: Limpar escape de aspas que podem estar causando problemas
            json_content = json_content.replace('\\"', '"')

            try:
                return json.loads(json_content)
            except json.JSONDecodeError as e:
                # Log do erro para debug e tentar parsear linha por linha
                print(f"Erro ao fazer parse do JSON em bloco: {e}")
                print(f"Conte√∫do original: {json_content[:500]}...")

                # Tentar corrigir escape duplo
                try:
                    json_content_fixed = json_content.replace('\\', '')
                    return json.loads(json_content_fixed)
                except json.JSONDecodeError:
                    pass

        # Estrat√©gia 2: Procurar por JSON direto no texto (sem markdown)
        # Padr√£o mais amplo para capturar estruturas JSON
        json_pattern = r'\{[^{}]*?"(?:periodo|regiao|cliente|produto|representante)"[^{}]*?\}|\{(?:[^{}]|"[^"]*")*?"(?:periodo|regiao|cliente|produto|representante)"(?:[^{}]|"[^"]*")*?\}'
        json_matches = re.findall(json_pattern, response_text, re.DOTALL)

        for match in json_matches:
            try:
                return json.loads(match)
            except json.JSONDecodeError:
                continue

        # Estrat√©gia 3: Procurar estrutura multi-linha mais complexa
        # Captura JSONs que podem ter quebras de linha
        multiline_pattern = r'\{[\s\S]*?"(?:periodo|regiao|cliente|produto|representante)"[\s\S]*?\}'
        multiline_matches = re.findall(multiline_pattern, response_text)

        for match in multiline_matches:
            try:
                return json.loads(match)
            except json.JSONDecodeError:
                continue

        # Estrat√©gia 4: Procurar JSON no final da response com padr√£o mais amplo
        # O modelo √†s vezes coloca JSON no final sem markdown
        json_patterns = [
            r'\{[^{}]*?\"periodo\"[^{}]*?\}(?:\s*json\s*)?$',  # Original
            r'\{[^{}]*?periodo[^{}]*?\}(?:\s*json\s*)?$',      # Sem aspas
            r'\{.*?periodo.*?\}(?:\s*json\s*)?$',              # Mais amplo
        ]

        for pattern in json_patterns:
            json_end_matches = re.findall(pattern, response_text, re.MULTILINE | re.DOTALL)

            for match in json_end_matches:
                # Limpar poss√≠vel sufixo 'json'
                clean_match = re.sub(r'\s*json\s*$', '', match.strip())

                # CORRE√á√ÉO: Limpar diferentes tipos de escape
                clean_match = clean_match.replace('\\\\\\\"', '\\"')  # Triple escape
                clean_match = clean_match.replace('\\\\\"', '\"')     # Double escape
                clean_match = clean_match.replace('\\"', '"')         # Single escape

                try:
                    return json.loads(clean_match)
                except json.JSONDecodeError:
                    # Tentar remover todos os escapes
                    try:
                        clean_match_fixed = clean_match.replace('\\', '')
                        return json.loads(clean_match_fixed)
                    except json.JSONDecodeError:
                        continue

        # Estrat√©gia 5: Procurar estrutura completa na response
        # Padr√£o para detectar estrutura de filtros mesmo sem JSON v√°lido
        if any(keyword in response_text.lower() for keyword in ['periodo', 'regiao', 'cliente', 'produto', 'representante']):
            return self._extrair_filtros_por_texto(response_text)

        return None

    def _extrair_filtros_por_texto(self, response_text: str) -> Dict:
        """
        Extrai filtros analisando texto quando JSON n√£o est√° dispon√≠vel
        VERS√ÉO APRIMORADA COM PRESERVA√á√ÉO DE GRANULARIDADE TEMPORAL

        Args:
            response_text: Texto da response

        Returns:
            Dict com estrutura de filtros preservando granularidade de m√™s/ano
        """
        filtros = {
            "periodo": {},
            "regiao": {"UF_Cliente": None, "Municipio_Cliente": None},
            "cliente": {"Cod_Cliente": None, "Cod_Segmento_Cliente": None},
            "produto": {
                "Cod_Familia_Produto": None,
                "Cod_Grupo_Produto": None,
                "Cod_Linha_Produto": None,
                "Des_Linha_Produto": None
            },
            "representante": {"Cod_Vendedor": None, "Cod_Regiao_Vendedor": None}
        }

        text_lower = response_text.lower()

        # DETEC√á√ÉO TEMPORAL COM PRESERVA√á√ÉO DE GRANULARIDADE
        # Usar TextNormalizer para an√°lise avan√ßada
        try:
            from src.text_normalizer import normalizer

            # Obter dados temporais estruturados
            structured_temporal = normalizer.get_structured_temporal_data(response_text)

            if structured_temporal and "periodo" in structured_temporal:
                filtros["periodo"] = structured_temporal["periodo"]
                # VALIDA√á√ÉO CR√çTICA: Verificar se interval foi detectado corretamente
                if "_debug_interval" in structured_temporal:
                    debug_info = structured_temporal["_debug_interval"]
                    # Log para debug mode apenas
                    filtros["_temporal_parsing_log"] = f"Interval detected: {debug_info['start_month_name']} to {debug_info['end_month_name']} via pattern {debug_info['pattern_used']}"
            else:
                # Fallback para parsing b√°sico se estruturado falhar
                self._apply_basic_temporal_parsing(text_lower, filtros)

        except Exception as e:
            # Fallback para parsing b√°sico em caso de erro
            self._apply_basic_temporal_parsing(text_lower, filtros)
            filtros["_temporal_parsing_error"] = str(e)

        # DETEC√á√ÉO GEOGR√ÅFICA APRIMORADA
        # UFs (siglas de estado)
        uf_pattern = r'\b([A-Z]{2})\b'
        uf_matches = re.findall(uf_pattern, response_text)
        if "UF_Cliente" in self.valores_validos:
            valid_ufs = [uf for uf in uf_matches if uf in self.valores_validos["UF_Cliente"]]
            if valid_ufs:
                filtros["regiao"]["UF_Cliente"] = valid_ufs

        # DETEC√á√ÉO RESTRITIVA DE CIDADES - APENAS CORRESPOND√äNCIA EXATA
        if "Municipio_Cliente" in self.valores_validos:
            for cidade_valida in self.valores_validos["Municipio_Cliente"]:
                cidade_patterns = [
                    cidade_valida.lower(),
                    cidade_valida.lower().replace(' ', ''),  # Sem espa√ßos
                    cidade_valida.lower().replace('√£', 'a').replace('√ß', 'c').replace('√µ', 'o'),  # Normalizado
                    # Padr√µes espec√≠ficos conhecidos
                    cidade_valida.lower().replace('s√£o', 'sao').replace('jo√£o', 'joao')
                ]

                for pattern in cidade_patterns:
                    # CORRE√á√ÉO: Busca APENAS por correspond√™ncia exata ou palavra completa
                    # Usar word boundary para evitar falsas correspond√™ncias
                    if (pattern == text_lower.strip() or  # Texto exato
                        f" {pattern} " in f" {text_lower} " or  # Palavra completa com espa√ßos
                        text_lower.startswith(f"{pattern} ") or  # Come√ßa com palavra
                        text_lower.endswith(f" {pattern}") or  # Termina com palavra
                        f"/{pattern}/" in text_lower or  # Entre barras (URLs)
                        f"'{pattern}'" in text_lower or  # Entre aspas simples
                        f'"{pattern}"' in text_lower):  # Entre aspas duplas
                        filtros["regiao"]["Municipio_Cliente"] = [cidade_valida]
                        break

                if filtros["regiao"]["Municipio_Cliente"]:
                    break

        # DETEC√á√ÉO DE SEGMENTOS DE CLIENTE
        segmento_patterns = {
            'atacado': ['ATACADO'],
            'varejo': ['VAREJO'],
            'industria': ['INDUSTRIA', 'INDUSTRIAL'],
            'construcao': ['CONSTRUCAO', 'CONSTRU√á√ÉO'],
            'agropecuario': ['AGROPECUARIO', 'AGROPECU√ÅRIA'],
        }

        for palavra_chave, segmentos_validos in segmento_patterns.items():
            if palavra_chave in text_lower:
                if "Cod_Segmento_Cliente" in self.valores_validos:
                    # Verificar se algum dos segmentos v√°lidos existe no dataset
                    for segmento in segmentos_validos:
                        if segmento in self.valores_validos["Cod_Segmento_Cliente"]:
                            filtros["cliente"]["Cod_Segmento_Cliente"] = [segmento]
                            break

        # DETEC√á√ÉO DE PRODUTOS POR PALAVRAS-CHAVE
        produto_keywords = {
            'tubos': ['Des_Linha_Produto'],
            'conexoes': ['Des_Linha_Produto'],
            'soldavel': ['Des_Linha_Produto'],
            'esgoto': ['Des_Linha_Produto'],
            'pvc': ['Des_Linha_Produto'],
        }

        for keyword, campos in produto_keywords.items():
            if keyword in text_lower:
                for campo in campos:
                    if campo in self.valores_validos:
                        # Buscar produtos que contenham a palavra-chave
                        produtos_encontrados = [
                            p for p in self.valores_validos[campo]
                            if keyword.upper() in str(p).upper()
                        ]
                        if produtos_encontrados:
                            filtros["produto"][campo] = produtos_encontrados[:3]  # Limitar a 3 primeiros
                            break

        return filtros

    def _apply_basic_temporal_parsing(self, text_lower: str, filtros: Dict) -> None:
        """
        Aplica parsing temporal b√°sico como fallback - VERS√ÉO RESTRITIVA

        Args:
            text_lower: Texto em min√∫sculas
            filtros: Dicion√°rio de filtros a ser atualizado
        """
        # Padr√µes de data espec√≠ficos (mais restritivos)
        date_patterns = [
            r'(\d{4}-\d{2}-\d{2})',  # 2023-01-15
            r'(\d{2}/\d{2}/\d{4})',  # 15/01/2023
            # REMOVIDO: r'(\d{4})', - muito amplo, captura c√≥digos de cliente
        ]

        # Padr√£o de ano apenas em contexto temporal expl√≠cito
        year_context_patterns = [
            r'\b(?:ano|year)\s+(\d{4})\b',         # "ano 2023"
            r'\bem\s+(\d{4})\b',                   # "em 2024"
            r'\b(\d{4})\s*(?:ano|year)\b',         # "2023 ano"
            r'\bde\s+(\d{4})\b',                   # "de 2023"
            r'\b(\d{4})\s*[-/]\s*\d{1,2}\b',      # "2023-01", "2023/12"
        ]

        # Primeiro tentar padr√µes de data completos
        for pattern in date_patterns:
            matches = re.findall(pattern, text_lower)
            if matches:
                match = matches[0]
                # Validar se √© uma data plaus√≠vel (n√£o c√≥digo de cliente)
                if self._is_plausible_date(match):
                    filtros["periodo"]["Data"] = match
                    return

        # Depois tentar anos em contexto temporal
        for pattern in year_context_patterns:
            matches = re.findall(pattern, text_lower)
            if matches:
                year = matches[0]
                # Validar se √© um ano plaus√≠vel (1990-2030)
                if self._is_plausible_year(year):
                    filtros["periodo"]["Data"] = year
                    return

    def _is_plausible_date(self, date_str: str) -> bool:
        """
        Verifica se uma string representa uma data plaus√≠vel

        Args:
            date_str: String de data

        Returns:
            bool: True se √© data plaus√≠vel
        """
        try:
            if '-' in date_str:
                # Formato YYYY-MM-DD
                parts = date_str.split('-')
                if len(parts) == 3:
                    year, month, day = int(parts[0]), int(parts[1]), int(parts[2])
                    return (1990 <= year <= 2030 and 1 <= month <= 12 and 1 <= day <= 31)
            elif '/' in date_str:
                # Formato DD/MM/YYYY
                parts = date_str.split('/')
                if len(parts) == 3:
                    day, month, year = int(parts[0]), int(parts[1]), int(parts[2])
                    return (1990 <= year <= 2030 and 1 <= month <= 12 and 1 <= day <= 31)
            else:
                # Apenas ano
                year = int(date_str)
                return self._is_plausible_year(str(year))
        except (ValueError, IndexError):
            pass
        return False

    def _is_plausible_year(self, year_str: str) -> bool:
        """
        Verifica se uma string representa um ano plaus√≠vel

        Args:
            year_str: String do ano

        Returns:
            bool: True se √© ano plaus√≠vel (1990-2030)
        """
        try:
            year = int(year_str)
            return 1990 <= year <= 2030
        except ValueError:
            return False

    def _atualizar_filtros_do_json(self, json_filtros: Dict, contexto_atual: Dict) -> Tuple[Dict, List[str]]:
        """
        Atualiza filtros persistentes com base no JSON extra√≠do - VERS√ÉO MERGE INTELIGENTE APRIMORADA

        Args:
            json_filtros: Filtros extra√≠dos do JSON
            contexto_atual: Contexto atual

        Returns:
            Tuple[Dict, List[str]]: (contexto_atualizado, mudan√ßas)
        """
        mudancas = []
        # MUDAN√áA CR√çTICA: Come√ßar com contexto atual para preservar filtros existentes
        contexto_atualizado = copy.deepcopy(contexto_atual)

        # LOG: Estado inicial
        mudancas.append(f"Contexto inicial: {len(contexto_atual)} filtros ativos")

        # Comando de limpeza
        if json_filtros.get('clear_all_filters') or json_filtros.get('limpar_filtros'):
            self._limpar_todos_filtros()
            return {}, ["Todos os filtros foram removidos"]

        # LOG: JSON extra√≠do
        total_campos_json = sum(len(campos) for categoria, campos in json_filtros.items()
                              if categoria in ["periodo", "regiao", "cliente", "produto", "representante"])
        mudancas.append(f"JSON extra√≠do: {total_campos_json} campos em {len(json_filtros)} categorias")

        # MERGE INTELIGENTE: Processar cada categoria com estrat√©gia de combina√ß√£o
        contexto_antes_merge = len(contexto_atualizado)
        for categoria, campos in json_filtros.items():
            if categoria in ["periodo", "regiao", "cliente", "produto", "representante"]:
                mudancas_categoria = self._processar_categoria_com_merge(
                    categoria, campos, contexto_atualizado
                )
                mudancas.extend(mudancas_categoria)

        # Processar remo√ß√µes expl√≠citas
        if json_filtros.get('remover_filtros'):
            mudancas_remocao = self._processar_remocoes(json_filtros['remover_filtros'], contexto_atualizado)
            mudancas.extend(mudancas_remocao)

        # VALIDA√á√ÉO DE SANIDADE: Detectar perda de filtros
        contexto_depois_merge = len(contexto_atualizado)
        if contexto_atual and contexto_depois_merge < len(contexto_atual):
            filtros_perdidos = set(contexto_atual.keys()) - set(contexto_atualizado.keys())
            if filtros_perdidos:
                mudancas.append(f"ALERTA: {len(filtros_perdidos)} filtros foram perdidos: {filtros_perdidos}")

        # LOG: Resultado final
        mudancas.append(f"Contexto final: {len(contexto_atualizado)} filtros ativos")

        return contexto_atualizado, mudancas

    def _processar_categoria_com_merge(self, categoria: str, campos: Dict, contexto: Dict) -> List[str]:
        """
        Processa filtros de uma categoria espec√≠fica COM MERGE INTELIGENTE CORRIGIDO

        Estrat√©gia CORRIGIDA:
        1. Se o JSON cont√©m `null` para um campo, PRESERVAR valor existente no contexto (CORRE√á√ÉO CR√çTICA)
        2. Se o JSON cont√©m valor, ADICIONAR/SOBRESCREVER dependendo do tipo
        3. Para listas, fazer merge; para valores √∫nicos, substituir
        4. GARANTIR que valores existentes n√£o sejam perdidos quando JSON tem null
        5. TRATAMENTO ESPECIAL para categoria 'periodo' com estrutura inicio/fim

        Args:
            categoria: Nome da categoria
            campos: Dicion√°rio com campos e valores do JSON
            contexto: Contexto sendo atualizado

        Returns:
            Lista de mudan√ßas realizadas
        """
        mudancas = []

        # TRATAMENTO ESPECIAL PARA CATEGORIA PER√çODO
        if categoria == "periodo":
            return self._processar_periodo_estruturado(campos, contexto)

        for campo, valor_json in campos.items():
            valor_existente = contexto.get(campo)

            # CORRE√á√ÉO CR√çTICA: Se JSON tem `null`, verificar se h√° valor existente para preservar
            if valor_json is None:
                # Se h√° valor existente no contexto, PRESERV√Å-LO explicitamente
                if valor_existente is not None and valor_existente != [] and valor_existente != "":
                    # Manter o valor existente - n√£o remov√™-lo
                    mudancas.append(f"Preservado: {campo} = {valor_existente} (JSON null, mas valor existe)")
                # Se n√£o h√° valor existente, realmente n√£o fazer nada
                continue

            # REGRA 2: Se JSON tem valor, aplicar merge inteligente com valida√ß√£o aprimorada

            # Validar valores do JSON com logs detalhados
            if isinstance(valor_json, list):
                valores_validos = self.validar_valores(campo, valor_json, categoria)
                if not valores_validos and valor_json:  # Log apenas se havia valores mas foram rejeitados
                    mudancas.append(f"Rejeitados valores inv√°lidos para {campo}: {valor_json}")
            else:
                valores_validos = self.validar_valores(campo, [valor_json], categoria)
                if valores_validos:
                    valores_validos = valores_validos[0]  # √önico valor
                elif valor_json:  # Log apenas se havia valor mas foi rejeitado
                    mudancas.append(f"Rejeitado valor inv√°lido para {campo}: {valor_json}")

            # CORRE√á√ÉO: N√£o pular se valores_validos est√° vazio - aplicar fallback para preserva√ß√£o
            if not valores_validos:
                # FALLBACK: Se valida√ß√£o falhou mas h√° valor no JSON, tentar preservar valor existente
                if valor_existente is not None and valor_existente != [] and valor_existente != "":
                    mudancas.append(f"Preservado por fallback: {campo} = {valor_existente} (valida√ß√£o falhou)")
                continue

            # MERGE STRATEGY baseado no tipo de campo
            if self._campo_permite_multiplos_valores(campo):
                # Campos que permitem listas (ex: Municipio_Cliente)
                valores_finais = self._merge_lista_valores(valor_existente, valores_validos)
                if valores_finais != valor_existente:
                    contexto[campo] = valores_finais
                    mudancas.append(f"+ Merged: {campo} = {valores_finais}")
            else:
                # Campos √∫nicos (ex: Data) - substituir sempre
                if valores_validos != valor_existente:
                    contexto[campo] = valores_validos
                    if valor_existente:
                        mudancas.append(f"* Atualizado: {campo} de '{valor_existente}' para '{valores_validos}'")
                    else:
                        mudancas.append(f"+ Adicionado: {campo} = {valores_validos}")

        return mudancas

    def _processar_periodo_estruturado(self, campos: Dict, contexto: Dict) -> List[str]:
        """
        Processa categoria per√≠odo com tratamento especial para estruturas inicio/fim.

        Args:
            campos: Campos da categoria per√≠odo do JSON
            contexto: Contexto sendo atualizado

        Returns:
            Lista de mudan√ßas realizadas
        """
        mudancas = []

        # CASO 1: Estrutura inicio/fim (intervalo)
        if "inicio" in campos and "fim" in campos:
            inicio = campos["inicio"]
            fim = campos["fim"]

            if inicio and fim and isinstance(inicio, dict) and isinstance(fim, dict):
                # Converter estrutura para Data_>= e Data_<
                try:
                    from src.text_normalizer import normalizer

                    # Construir dados estruturados tempor√°rios para convers√£o
                    structured_data = {
                        "periodo": {
                            "inicio": inicio,
                            "fim": fim
                        }
                    }

                    # Converter para ranges
                    ranges = normalizer.convert_structured_to_ranges(structured_data)

                    if ranges and "Data_>=" in ranges and "Data_<" in ranges:
                        # Limpar filtros de data existentes
                        for key in list(contexto.keys()):
                            if key.startswith("Data"):
                                del contexto[key]

                        # Adicionar novos ranges
                        contexto["Data_>="] = ranges["Data_>="]
                        contexto["Data_<"] = ranges["Data_<"]

                        mudancas.append(f"+ Interval: {inicio['mes']}/{inicio['ano']} at√© {fim['mes']}/{fim['ano']} ‚Üí {ranges['Data_>=']} at√© {ranges['Data_<']}")
                    else:
                        mudancas.append("‚ùå Falha ao converter interval para ranges de data")

                except Exception as e:
                    mudancas.append(f"‚ùå Erro ao processar interval: {str(e)}")

        # CASO 2: M√™s/ano √∫nico
        elif "mes" in campos and "ano" in campos:
            mes = campos["mes"]
            ano = campos["ano"]

            if mes and ano:
                try:
                    from src.text_normalizer import normalizer

                    # Construir dados estruturados tempor√°rios
                    structured_data = {
                        "periodo": {
                            "mes": mes,
                            "ano": ano
                        }
                    }

                    # Converter para ranges
                    ranges = normalizer.convert_structured_to_ranges(structured_data)

                    if ranges and "Data_>=" in ranges and "Data_<" in ranges:
                        # Limpar filtros de data existentes
                        for key in list(contexto.keys()):
                            if key.startswith("Data"):
                                del contexto[key]

                        # Adicionar novos ranges
                        contexto["Data_>="] = ranges["Data_>="]
                        contexto["Data_<"] = ranges["Data_<"]

                        mudancas.append(f"+ M√™s √∫nico: {mes}/{ano} ‚Üí {ranges['Data_>=']} at√© {ranges['Data_<']}")
                    else:
                        mudancas.append("‚ùå Falha ao converter m√™s/ano para ranges de data")

                except Exception as e:
                    mudancas.append(f"‚ùå Erro ao processar m√™s/ano: {str(e)}")

        # CASO 3: Data ranges diretos (compatibilidade)
        elif "Data_>=" in campos or "Data_<" in campos:
            for campo in ["Data_>=", "Data_<"]:
                if campo in campos and campos[campo]:
                    contexto[campo] = campos[campo]
                    mudancas.append(f"+ Data range: {campo} = {campos[campo]}")

        # CASO 4: Data simples (compatibilidade)
        elif "Data" in campos and campos["Data"]:
            contexto["Data"] = campos["Data"]
            mudancas.append(f"+ Data: {campos['Data']}")

        return mudancas

    def _campo_permite_multiplos_valores(self, campo: str) -> bool:
        """
        Determina se um campo pode ter m√∫ltiplos valores (lista)

        Args:
            campo: Nome do campo

        Returns:
            bool: True se permite lista de valores
        """
        # Campos que tradicionalmente aceitam listas
        campos_lista = [
            'UF_Cliente', 'Municipio_Cliente', 'Cod_Cliente', 'Cod_Segmento_Cliente',
            'Cod_Familia_Produto', 'Cod_Grupo_Produto', 'Cod_Linha_Produto', 'Des_Linha_Produto',
            'Cod_Vendedor', 'Cod_Regiao_Vendedor'
        ]

        # Campos temporais geralmente s√£o √∫nicos
        campos_unicos = ['Data', 'Data_>=', 'Data_<', 'periodo', 'mes', 'ano']

        if campo in campos_unicos:
            return False
        elif campo in campos_lista:
            return True
        else:
            # Default: permitir listas para campos n√£o reconhecidos
            return True

    def _merge_lista_valores(self, valor_existente, novo_valor):
        """
        Merge inteligente de listas de valores

        Args:
            valor_existente: Valor atual (pode ser None, string, ou lista)
            novo_valor: Novo valor (pode ser string ou lista)

        Returns:
            Lista merged ou valor √∫nico
        """
        # Normalizar para listas
        existente_lista = []
        if valor_existente:
            if isinstance(valor_existente, list):
                existente_lista = valor_existente.copy()
            else:
                existente_lista = [valor_existente]

        novo_lista = []
        if isinstance(novo_valor, list):
            novo_lista = novo_valor.copy()
        else:
            novo_lista = [novo_valor]

        # Merge sem duplicatas, preservando ordem
        resultado = existente_lista.copy()
        for item in novo_lista:
            if item not in resultado:
                resultado.append(item)

        # Retornar lista ou valor √∫nico baseado no tamanho
        if len(resultado) == 1:
            return resultado[0]
        else:
            return resultado

    def _processar_categoria(self, categoria: str, campos: Dict, contexto: Dict) -> List[str]:
        """
        Processa filtros de uma categoria espec√≠fica

        Args:
            categoria: Nome da categoria
            campos: Dicion√°rio com campos e valores
            contexto: Contexto sendo atualizado

        Returns:
            Lista de mudan√ßas realizadas
        """
        mudancas = []

        for campo, valor in campos.items():
            if valor is None:
                continue

            # Validar valores
            if isinstance(valor, list):
                valores_validos = self.validar_valores(campo, valor, categoria)
            else:
                valores_validos = self.validar_valores(campo, [valor], categoria)
                if valores_validos:
                    valores_validos = valores_validos[0]  # √önico valor

            # Atualizar contexto se h√° valores v√°lidos
            if valores_validos:
                contexto[campo] = valores_validos
                mudancas.append(f"+ Adicionado: {campo} = {valores_validos}")

        return mudancas

    def _processar_remocoes(self, remover_filtros: List[str], contexto: Dict) -> List[str]:
        """
        Processa remo√ß√µes expl√≠citas de filtros

        Args:
            remover_filtros: Lista de filtros para remover
            contexto: Contexto sendo atualizado

        Returns:
            Lista de mudan√ßas realizadas
        """
        mudancas = []

        for filtro in remover_filtros:
            if filtro in contexto:
                valor_removido = contexto[filtro]
                del contexto[filtro]
                mudancas.append(f"- Removido: {filtro} = {valor_removido}")

        return mudancas

    def _limpar_todos_filtros(self):
        """Limpa todos os filtros persistentes"""
        self.filtros_persistentes = {
            "periodo": {"Data": None},
            "regiao": {"UF_Cliente": [], "Municipio_Cliente": []},
            "cliente": {"Cod_Cliente": [], "Cod_Segmento_Cliente": []},
            "produto": {
                "Cod_Familia_Produto": [],
                "Cod_Grupo_Produto": [],
                "Cod_Linha_Produto": [],
                "Des_Linha_Produto": []
            },
            "representante": {"Cod_Vendedor": [], "Cod_Regiao_Vendedor": []}
        }

    def sincronizar_com_contexto_agente(self, contexto_agente: Dict) -> bool:
        """
        Sincroniza filtros persistentes com contexto do agente

        Args:
            contexto_agente: Contexto do agente

        Returns:
            True se houve mudan√ßas
        """
        houve_mudancas = False

        # Atualizar filtros persistentes com base no contexto do agente
        for campo, valor in contexto_agente.items():
            categoria = self._determinar_categoria(campo)
            if categoria and valor is not None:
                if categoria not in self.filtros_persistentes:
                    self.filtros_persistentes[categoria] = {}

                if self.filtros_persistentes[categoria].get(campo) != valor:
                    self.filtros_persistentes[categoria][campo] = valor
                    houve_mudancas = True

        return houve_mudancas

    def _determinar_categoria(self, campo: str) -> Optional[str]:
        """
        Determina a categoria de um campo

        Args:
            campo: Nome do campo

        Returns:
            Nome da categoria ou None
        """
        campo_lower = campo.lower()

        if campo_lower in ['data', 'data_>=', 'data_<', 'periodo', 'mes', 'ano']:
            return "periodo"
        elif campo_lower in ['uf_cliente', 'municipio_cliente', 'cidade', 'estado']:
            return "regiao"
        elif campo_lower in ['cod_cliente', 'cod_segmento_cliente', 'cliente']:
            return "cliente"
        elif any(x in campo_lower for x in ['produto', 'familia', 'grupo', 'linha']):
            return "produto"
        elif any(x in campo_lower for x in ['vendedor', 'representante', 'regiao_vendedor']):
            return "representante"

        return None

    def obter_contexto_para_agente(self) -> Dict:
        """
        Converte filtros persistentes para formato de contexto do agente

        Returns:
            Dicion√°rio no formato esperado pelo agente
        """
        contexto = {}

        for categoria, campos in self.filtros_persistentes.items():
            for campo, valor in campos.items():
                if valor is not None and valor != [] and valor != "":
                    contexto[campo] = valor

        return contexto

    def obter_resumo_filtros_ativos(self) -> str:
        """
        Gera resumo textual dos filtros ativos

        Returns:
            String com resumo dos filtros
        """
        filtros_ativos = []

        for categoria, campos in self.filtros_persistentes.items():
            count = sum(1 for v in campos.values() if v is not None and v != [] and v != "")
            if count > 0:
                nome_categoria = {
                    "periodo": "temporal",
                    "regiao": "geogr√°fico",
                    "cliente": "cliente",
                    "produto": "produto",
                    "representante": "representante"
                }.get(categoria, categoria)
                filtros_ativos.append(f"{count} {nome_categoria}")

        if not filtros_ativos:
            return "Nenhum filtro ativo"

        return f"Filtros ativos: {', '.join(filtros_ativos)}"

    def aplicar_filtros_desabilitados(self, contexto: Dict, filtros_desabilitados: Set[str]) -> Dict:
        """
        Remove filtros desabilitados do contexto

        Args:
            contexto: Contexto atual
            filtros_desabilitados: Set com IDs de filtros desabilitados

        Returns:
            Contexto filtrado
        """
        if not filtros_desabilitados:
            return contexto

        contexto_filtrado = {}

        for campo, valor in contexto.items():
            filter_id = f"{campo}:{valor}"

            # Tratamento especial para ranges de data
            if campo in ['Data_>=', 'Data_<'] and 'Data_>=' in contexto and 'Data_<' in contexto:
                start_date = contexto.get('Data_>=')
                end_date = contexto.get('Data_<')
                if start_date and end_date:
                    range_id = f"Data_range:{start_date}_{end_date}"
                    if range_id not in filtros_desabilitados:
                        contexto_filtrado[campo] = valor
            elif filter_id not in filtros_desabilitados:
                contexto_filtrado[campo] = valor

        return contexto_filtrado


# Inst√¢ncia global para uso em toda a aplica√ß√£o
_global_json_filter_manager: Optional[JSONFilterManager] = None


def get_json_filter_manager(df_dataset: pd.DataFrame) -> JSONFilterManager:
    """
    Singleton para obter inst√¢ncia global do JSONFilterManager

    Args:
        df_dataset: DataFrame com dados

    Returns:
        Inst√¢ncia do JSONFilterManager
    """
    global _global_json_filter_manager

    if _global_json_filter_manager is None:
        _global_json_filter_manager = JSONFilterManager(df_dataset)

    return _global_json_filter_manager


def reset_json_filter_manager():
    """Reset da inst√¢ncia global (√∫til para testes)"""
    global _global_json_filter_manager
    _global_json_filter_manager = None


def detectar_filtros_na_pergunta(pergunta_usuario: str, df_dataset: pd.DataFrame) -> Dict:
    """
    Detecta filtros automaticamente na pergunta original do usu√°rio
    VERS√ÉO COM PRESERVA√á√ÉO DE GRANULARIDADE TEMPORAL

    Args:
        pergunta_usuario: Pergunta original do usu√°rio
        df_dataset: DataFrame para valida√ß√£o

    Returns:
        Dict com filtros detectados preservando granularidade de m√™s/ano
    """
    manager = get_json_filter_manager(df_dataset)

    # Usar extra√ß√£o de texto aprimorada com TextNormalizer
    filtros_detectados = manager._extrair_filtros_por_texto(pergunta_usuario)

    # DETEC√á√ÉO ESPEC√çFICA PARA PERGUNTA (complementar)
    pergunta_lower = pergunta_usuario.lower()

    # Detectar termos geogr√°ficos comuns nas perguntas - BUSCA PRECISA
    termos_geograficos = {
        'joinville': 'JOINVILLE',
        'florianopolis': 'FLORIANOPOLIS',
        'florian√≥polis': 'FLORIANOPOLIS',
        'sao paulo': 'SAO PAULO',
        's√£o paulo': 'SAO PAULO',
        'rio de janeiro': 'RIO DE JANEIRO',
        'porto alegre': 'PORTO ALEGRE',
        'curitiba': 'CURITIBA',
        'belo horizonte': 'BELO HORIZONTE',
        'brasilia': 'BRASILIA',
        'bras√≠lia': 'BRASILIA',
        'salvador': 'SALVADOR',
        'fortaleza': 'FORTALEZA'
    }

    for termo, cidade_oficial in termos_geograficos.items():
        # BUSCA PRECISA: palavra completa com boundary
        if (f" {termo} " in f" {pergunta_lower} " or
            pergunta_lower.startswith(f"{termo} ") or
            pergunta_lower.endswith(f" {termo}") or
            pergunta_lower == termo):

            if "Municipio_Cliente" in manager.valores_validos:
                if cidade_oficial in manager.valores_validos["Municipio_Cliente"]:
                    if not filtros_detectados["regiao"]["Municipio_Cliente"]:
                        filtros_detectados["regiao"]["Municipio_Cliente"] = [cidade_oficial]
                    break

    # Detectar ranking/top patterns que podem indicar filtros impl√≠citos
    ranking_patterns = [
        r'top\s+(\d+)',
        r'principais?\s+(\d+)?',
        r'maiores?\s+(\d+)?',
        r'melhores?\s+(\d+)?'
    ]

    for pattern in ranking_patterns:
        if re.search(pattern, pergunta_lower):
            # Se √© uma pergunta de ranking, pode ser que precise de contexto mais espec√≠fico
            # Mas deixar vazio para permitir an√°lise geral se n√£o h√° outros filtros
            break

    return filtros_detectados


def processar_filtros_automaticos(response_text: str, contexto_atual: Dict, df_dataset: pd.DataFrame, pergunta_usuario: str = "") -> Tuple[Dict, List[str]]:
    """
    Fun√ß√£o principal para processar filtros autom√°ticos - VERS√ÉO REFATORADA COM EXTRA√á√ÉO SQL

    Esta fun√ß√£o agora prioriza a extra√ß√£o de filtros das queries SQL executadas,
    usando o sistema baseado em texto como fallback para compatibilidade.

    Args:
        response_text: Texto da response do modelo
        contexto_atual: Contexto atual de filtros
        df_dataset: DataFrame com dados para valida√ß√£o
        pergunta_usuario: Pergunta original do usu√°rio (usado como fallback)

    Returns:
        Tuple[Dict, List[str]]: (contexto_atualizado, lista_de_mudan√ßas)
    """
    # NOTA: Esta fun√ß√£o √© mantida para compatibilidade, mas a l√≥gica principal
    # foi movida para app.py onde temos acesso ao debug_info com queries SQL.
    # Aqui implementamos apenas o fallback baseado em texto.

    manager = get_json_filter_manager(df_dataset)
    mudancas = []

    # Implementar fallback baseado no sistema original
    contexto_atualizado = contexto_atual.copy()

    if pergunta_usuario.strip():
        filtros_pergunta = detectar_filtros_na_pergunta(pergunta_usuario, df_dataset)

        # VALIDA√á√ÉO CR√çTICA: Verificar se detectou intervalos temporais
        if filtros_pergunta and "periodo" in filtros_pergunta:
            periodo_info = filtros_pergunta["periodo"]
            # Se detectou interval com in√≠cio e fim, priorizar sempre
            if "inicio" in periodo_info and "fim" in periodo_info:
                contexto_da_pergunta, mudancas_pergunta = manager._atualizar_filtros_do_json(filtros_pergunta, contexto_atual)
                mudancas.extend(["üéØ INTERVAL detectado na pergunta original:"] + mudancas_pergunta)
                contexto_atualizado = contexto_da_pergunta
            else:
                # Single month/year - ainda priorit√°rio mas check response tamb√©m
                contexto_da_pergunta, mudancas_pergunta = manager._atualizar_filtros_do_json(filtros_pergunta, contexto_atual)
                if mudancas_pergunta and any(change.startswith("+") or change.startswith("*") for change in mudancas_pergunta):
                    mudancas.extend(["üîç Detectado na pergunta original:"] + mudancas_pergunta)
                    contexto_atualizado = contexto_da_pergunta
        else:
            # Sem per√≠odo detectado na pergunta, processar outros filtros
            contexto_da_pergunta, mudancas_pergunta = manager._atualizar_filtros_do_json(filtros_pergunta, contexto_atual)
            if mudancas_pergunta and any(change.startswith("+") or change.startswith("*") for change in mudancas_pergunta):
                mudancas.extend(["üîç Detectado na pergunta original:"] + mudancas_pergunta)
                contexto_atualizado = contexto_da_pergunta

    # ESTRAT√âGIA 2: COMPLEMENTAR COM AN√ÅLISE DA RESPONSE (se necess√°rio)
    # Apenas se n√£o detectou intervalo temporal na pergunta
    pergunta_tem_intervalo = False
    if contexto_atualizado:
        # Check se j√° tem interval complete do processamento da pergunta
        for campo, valor in contexto_atualizado.items():
            if campo.startswith('Data_') and 'Data_>=' in contexto_atualizado and 'Data_<' in contexto_atualizado:
                pergunta_tem_intervalo = True
                break

    if not pergunta_tem_intervalo:
        contexto_response, mudancas_response = manager.processar_json_response(response_text, contexto_atualizado)

        if mudancas_response and any(change.startswith("+") or change.startswith("*") for change in mudancas_response):
            mudancas.extend(["üìù Detectado na response:"] + mudancas_response)
            contexto_atualizado = contexto_response

    # LOG: Estrat√©gia utilizada
    if not mudancas:
        mudancas.append("‚ÑπÔ∏è Nenhum novo filtro detectado em pergunta ou response")
    else:
        # VALIDA√á√ÉO FINAL: Log do que foi detectado
        if 'Data_>=' in contexto_atualizado and 'Data_<' in contexto_atualizado:
            mudancas.append(f"‚úÖ Interval final: {contexto_atualizado['Data_>=']} at√© {contexto_atualizado['Data_<']}")

    return contexto_atualizado, mudancas


def processar_filtros_com_sql_prioritario(sql_queries: List[str], response_text: str,
                                         contexto_atual: Dict, df_dataset: pd.DataFrame,
                                         pergunta_usuario: str = "") -> Tuple[Dict, List[str]]:
    """
    Nova fun√ß√£o que prioriza extra√ß√£o de filtros das queries SQL

    Args:
        sql_queries: Lista de queries SQL executadas
        response_text: Texto da response do modelo (fallback)
        contexto_atual: Contexto atual de filtros
        df_dataset: DataFrame com dados para valida√ß√£o
        pergunta_usuario: Pergunta original do usu√°rio (fallback)

    Returns:
        Tuple[Dict, List[str]]: (contexto_atualizado, lista_de_mudan√ßas)
    """
    from .sql_filter_extractor import SQLFilterExtractor

    mudancas = []
    contexto_atualizado = contexto_atual.copy()

    if sql_queries:
        # ESTRAT√âGIA PRIORIT√ÅRIA: Extrair filtros das queries SQL
        extractor = SQLFilterExtractor(df_dataset)
        sql_filters = extractor.extract_filters_from_multiple_queries(sql_queries)

        if sql_filters and any(sql_filters.values()):
            # Converter para formato de contexto
            sql_context = _convert_sql_json_to_context(sql_filters)

            if sql_context:
                # Merge com contexto existente
                old_keys = set(contexto_atualizado.keys())
                contexto_atualizado.update(sql_context)
                new_keys = set(contexto_atualizado.keys())

                added_keys = new_keys - old_keys
                if added_keys:
                    mudancas.append(f"üéØ **Filtros extra√≠dos do SQL:** {len(added_keys)} filtros detectados")
                    for key in added_keys:
                        mudancas.append(f"  + {key} = {contexto_atualizado[key]}")

                return contexto_atualizado, mudancas

    # FALLBACK: Se n√£o conseguiu extrair do SQL, usar sistema original
    return processar_filtros_automaticos(response_text, contexto_atual, df_dataset, pergunta_usuario)


def _convert_sql_json_to_context(sql_filters: Dict) -> Dict:
    """
    Converte estrutura JSON de filtros extra√≠dos do SQL para formato de contexto

    Args:
        sql_filters: Filtros extra√≠dos em formato JSON

    Returns:
        Dict no formato de contexto do agente
    """
    context = {}

    for category, fields in sql_filters.items():
        if not isinstance(fields, dict) or not fields:
            continue

        if category == 'periodo':
            # Processar estrutura temporal
            if 'mes' in fields and 'ano' in fields:
                # M√™s espec√≠fico - converter para range
                mes = fields['mes']
                ano = fields['ano']
                try:
                    from datetime import datetime

                    # Normalizar mes e ano
                    if isinstance(mes, str) and mes.isdigit():
                        mes_int = int(mes)
                    elif isinstance(mes, int):
                        mes_int = mes
                    else:
                        raise ValueError("M√™s inv√°lido")

                    ano_int = int(ano)

                    start_date = f"{ano_int}-{mes_int:02d}-01"

                    # Calcular primeiro dia do pr√≥ximo m√™s
                    if mes_int == 12:
                        end_year = ano_int + 1
                        end_month = 1
                    else:
                        end_year = ano_int
                        end_month = mes_int + 1

                    end_date = f"{end_year}-{end_month:02d}-01"

                    context['Data_>='] = start_date
                    context['Data_<'] = end_date
                except (ValueError, TypeError):
                    # Fallback para formato simples
                    context['periodo'] = f"{mes}/{ano}"

            elif 'inicio' in fields and 'fim' in fields:
                # Intervalo de meses
                inicio = fields['inicio']
                fim = fields['fim']

                if isinstance(inicio, dict) and isinstance(fim, dict):
                    try:
                        start_mes = inicio.get('mes')
                        start_ano = inicio.get('ano')
                        end_mes = fim.get('mes')
                        end_ano = fim.get('ano')

                        if all([start_mes, start_ano, end_mes, end_ano]):
                            # Normalizar valores
                            start_mes_int = int(start_mes)
                            start_ano_int = int(start_ano)
                            end_mes_int = int(end_mes)
                            end_ano_int = int(end_ano)

                            start_date = f"{start_ano_int}-{start_mes_int:02d}-01"

                            # Calcular primeiro dia do m√™s seguinte ao fim
                            if end_mes_int == 12:
                                next_year = end_ano_int + 1
                                next_month = 1
                            else:
                                next_year = end_ano_int
                                next_month = end_mes_int + 1

                            end_date = f"{next_year}-{next_month:02d}-01"

                            context['Data_>='] = start_date
                            context['Data_<'] = end_date
                    except (ValueError, TypeError):
                        # Fallback
                        context['periodo'] = f"{inicio} at√© {fim}"

            # Campos diretos de data
            for field, value in fields.items():
                if field in ['Data_>=', 'Data_<', 'Data_<=', 'Data_>', 'Data']:
                    context[field] = value

        else:
            # Para outras categorias, mapear campos diretamente
            for field, value in fields.items():
                if value is not None and value != [] and value != "":
                    context[field] = value

    return context